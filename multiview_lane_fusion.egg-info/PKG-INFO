Metadata-Version: 2.4
Name: multiview-lane-fusion
Version: 0.1.0
Summary: Multi-view Lane Fusion Library
Requires-Python: ==3.10.*
Description-Content-Type: text/markdown
Requires-Dist: torch==2.1.0
Requires-Dist: torchvision==0.16.0
Requires-Dist: torchaudio==2.1.0
Requires-Dist: mmcv==2.1.0
Requires-Dist: mmengine==0.10.7
Requires-Dist: mmdet==3.2.0
Requires-Dist: numpy==1.26.4
Requires-Dist: opencv-python>=4.8.0
Requires-Dist: autodistill>=0.1.0
Requires-Dist: autodistill-grounded-sam>=0.1.0
Requires-Dist: transformers<4.40.0
Requires-Dist: tokenizers<0.19.0
Requires-Dist: roboflow
Requires-Dist: scikit-learn
Requires-Dist: Pillow
Requires-Dist: rerun-sdk==0.19.0
Requires-Dist: pyyaml

# multiview-lane-fusion

███╗ ███╗██╗ ██╗██╗ ████████╗██╗██╗ ██╗██╗███████╗██╗ ██╗
████╗ ████║██║ ██║██║ ╚══██╔══╝██║██║ ██║██║██╔════╝██║ ██║
██╔████╔██║██║ ██║██║ ██║ ██║██║ ██║██║█████╗ ██║ ██║
██║╚██╔╝██║██║ ██║██║ ██║ ██║╚██╗ ██╔╝██║██╔══╝ ██║ █ ██║
██║ ╚═╝ ██║╚██████╔╝███████╗██║ ██║ ╚████╔╝ ██║███████╗╚██╗ ██╔╝
╚═╝ ╚═╝ ╚═════╝ ╚══════╝╚═╝ ╚═╝ ╚═══╝ ╚═╝╚══════╝ ╚═╝ ╚═╝
██╗ █████╗ ███╗ ██╗███████╗
██║ ██╔══██╗████╗ ██║██╔════╝
██║ ███████║██╔██╗ ██║█████╗
██║ ██╔══██║██║╚██╗██║██╔══╝
███████╗██║ ██║██║ ╚████║███████╗
╚══════╝╚═╝ ╚═╝╚═╝ ╚═══╝╚══════╝

Multi-view Lane Fusion Library — lane detection and fusion across multiple camera views.

## Prerequisites

- **Python 3.10**
- **uv** (recommended) — [Astral’s uv](https://docs.astral.sh/uv/) for fast, reproducible installs
- **CUDA 12.1** (optional, for GPU) — install steps below use CUDA 12.1 builds

## Installation

### 1. Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

Add uv to your PATH and reload your shell:

```bash
echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
source ~/.bashrc
uv --version
```

### 2. Create and activate a virtual environment

```bash
uv venv .venv --python 3.10
source .venv/bin/activate
```

On Windows (PowerShell): `.venv\Scripts\activate`

### 3. Install dependencies (CUDA 12.1 / GPU)

For GPU support with CUDA 12.1, install in this order:

```bash
uv pip uninstall numpy -y
uv pip install numpy==1.26.4

uv pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 \
  --index-url https://download.pytorch.org/whl/cu121

uv pip install mmcv==2.1.0 \
  -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html

uv pip install mmdet==3.2.0


uv pip install "autodistill>=0.1.0"
uv pip install "autodistill-grounded-sam>=0.1.0"
uv pip install "roboflow==1.2.11"
uv pip install scikit-learn


```

**CPU-only or after syncing from lockfile:** from the project root run:

```bash
uv sync
```

### 4. Verify the installation

Basic stack check:

```bash
python - << 'EOF'
import torch, mmcv
from mmcv.ops import batched_nms
print("Torch:", torch.__version__)
print("MMCV:", mmcv.__version__)
print("batched_nms OK")
EOF
```

Full stack (including MMEngine and MMDet):

```bash
python - << 'EOF'
import torch, mmcv, mmengine, mmdet
print("Torch:", torch.__version__)
print("MMCV:", mmcv.__version__)
print("MMEngine:", mmengine.__version__)
print("MMDet:", mmdet.__version__)
EOF
```

Check that DCNv2 (Deformable Convolution) is available:

```bash
python - << 'EOF'
from mmcv.ops import DeformConv2d
print("DCNv2 available")
EOF
```

Package imports:

```bash
python -c "from lane_fusion import MultiViewImagePreprocessor; from SegmentationToolkit import MaskGenerator; print('Packages OK')"
```

## Run

```bash
uv run --no-sync python backbone_builder.py
```

With venv already activated:

```bash
python backbone_builder.py
```

## Etiquetado (Semantic Segmentation Labeling)

Launch the Rerun-based labeling tool with GUI controls:

```bash
cd SegmentationToolkit
uv run python SegmentationToolkit/autolabel_rerun.py
```

With venv already activated:

```bash
cd SegmentationToolkit
python autolabel_rerun.py
```

>Important: Ensure to have images in SegmentatioToolkit/data/raw_images


## Clean up

To remove the environment and uv cache and start over:

```bash
deactivate
rm -rf .venv
uv cache clean
```
